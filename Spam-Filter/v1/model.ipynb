{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter from scratch using naiive bayes\n",
    "\n",
    "\n",
    "based on the article : https://towardsdatascience.com/na%C3%AFve-bayes-spam-filter-from-scratch-12970ad3dae7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training and Testing Data\n",
    "\n",
    "train_spam = ['send us your password'  , 'review our website' , 'send your password' , 'send us your account']\n",
    "\n",
    "train_ham = ['Your activity report' ,'benefits physical activity' , 'the importance vows']\n",
    "\n",
    "test_emails = {'spam':['renew your password' ,'revew your vows'],\n",
    "               'ham' : ['benefits of our account' , 'the importance of physical activity']\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of spam emails with the word send: 3\n",
      "Spamicity of the word 'send' : 0.6666666666666666\n",
      "\n",
      "Number of spam emails with the word us: 2\n",
      "Spamicity of the word 'us' : 0.5\n",
      "\n",
      "Number of spam emails with the word your: 3\n",
      "Spamicity of the word 'your' : 0.6666666666666666\n",
      "\n",
      "Number of spam emails with the word password: 2\n",
      "Spamicity of the word 'password' : 0.5\n",
      "\n",
      "Number of spam emails with the word review: 1\n",
      "Spamicity of the word 'review' : 0.3333333333333333\n",
      "\n",
      "Number of spam emails with the word our: 4\n",
      "Spamicity of the word 'our' : 0.8333333333333334\n",
      "\n",
      "Number of spam emails with the word website: 1\n",
      "Spamicity of the word 'website' : 0.3333333333333333\n",
      "\n",
      "Number of spam emails with the word account: 1\n",
      "Spamicity of the word 'account' : 0.3333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# calculating how likely a word is to appear in a spam email\n",
    "\n",
    "vocab_words_spam = []\n",
    "for sentence in train_spam:\n",
    "    sentence_as_list = sentence.split()\n",
    "    for word in sentence_as_list:\n",
    "        vocab_words_spam.append(word)\n",
    "\n",
    "vocab_unique_words_spam = list(dict.fromkeys(vocab_words_spam))        \n",
    "\n",
    "dict_spamicity = {}\n",
    "for w in vocab_unique_words_spam:\n",
    "    emails_with_w = 0 \n",
    "    for sentence in train_spam:\n",
    "        if w in sentence:\n",
    "            emails_with_w += 1\n",
    "    print(f'Number of spam emails with the word {w}: {emails_with_w}')\n",
    "    total_spam = len(train_spam)\n",
    "    spamicity = (emails_with_w+1) / (total_spam+2)\n",
    "    print(f\"Spamicity of the word '{w}' : {spamicity}\\n\")\n",
    "    dict_spamicity[w.lower()] = spamicity\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ham emails with the word Your: 1\n",
      "Hamicity of the word 'Your' : 0.4\n",
      "\n",
      "Number of ham emails with the word activity: 2\n",
      "Hamicity of the word 'activity' : 0.6\n",
      "\n",
      "Number of ham emails with the word report: 1\n",
      "Hamicity of the word 'report' : 0.4\n",
      "\n",
      "Number of ham emails with the word benefits: 1\n",
      "Hamicity of the word 'benefits' : 0.4\n",
      "\n",
      "Number of ham emails with the word physical: 1\n",
      "Hamicity of the word 'physical' : 0.4\n",
      "\n",
      "Number of ham emails with the word the: 1\n",
      "Hamicity of the word 'the' : 0.4\n",
      "\n",
      "Number of ham emails with the word importance: 1\n",
      "Hamicity of the word 'importance' : 0.4\n",
      "\n",
      "Number of ham emails with the word vows: 1\n",
      "Hamicity of the word 'vows' : 0.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating how likely a word is to appear in a ham email\n",
    "\n",
    "vocab_words_ham = []\n",
    "for sentence in train_ham:\n",
    "    sentence_as_list = sentence.split()\n",
    "    for word in sentence_as_list:\n",
    "        vocab_words_ham.append(word)\n",
    "\n",
    "vocab_unique_words_ham = list(dict.fromkeys(vocab_words_ham))        \n",
    "\n",
    "\n",
    "dict_hamicity = {}\n",
    "for w in vocab_unique_words_ham:\n",
    "    emails_with_w = 0 \n",
    "    for sentence in train_ham:\n",
    "        if w in sentence:\n",
    "            emails_with_w += 1\n",
    "    print(f'Number of ham emails with the word {w}: {emails_with_w}')\n",
    "    total_ham = len(train_ham)\n",
    "    hamicity = (emails_with_w+1) / (total_ham+2)\n",
    "    print(f\"Hamicity of the word '{w}' : {hamicity}\\n\")\n",
    "    dict_hamicity[w.lower()] = hamicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the Probability of Spam P(S):\n",
    "    \n",
    "prob_spam = len(train_spam) / ( len(train_spam) + len(train_ham) ) \n",
    "prob_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the probability of Ham P(!S):\n",
    "\n",
    "prob_ham = len(train_ham) / ( len(train_spam) + len(train_ham) )\n",
    "\n",
    "prob_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['renew', 'your', 'password'],\n",
       " ['revew', 'your', 'vows'],\n",
       " ['benefits', 'of', 'our', 'account'],\n",
       " ['the', 'importance', 'of', 'physical', 'activity']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process test emails\n",
    "\n",
    "tests = []\n",
    "\n",
    "for i in test_emails['spam']:\n",
    "    tests.append(i)\n",
    "for i in test_emails['ham']:\n",
    "    tests.append(i)\n",
    "\n",
    "distinct_words_as_sentences_test = []\n",
    "for sentence in tests:\n",
    "    sentence_as_list = sentence.split()\n",
    "    senten = []\n",
    "    for word in sentence_as_list:\n",
    "        senten.append(word)    \n",
    "    distinct_words_as_sentences_test.append(senten)\n",
    "test_spam_tokenized = [distinct_words_as_sentences_test[0],\n",
    "                      distinct_words_as_sentences_test[1]]\n",
    "\n",
    "test_ham_tokenized = [distinct_words_as_sentences_test[2],\n",
    "                     distinct_words_as_sentences_test[3]]\n",
    "\n",
    "distinct_words_as_sentences_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'renew' , word not present in labelled spam training data\n",
      "'your',ok\n",
      "'password',ok\n",
      " 'revew' , word not present in labelled spam training data\n",
      "'your',ok\n",
      "'vows',ok\n",
      "'benefits',ok\n",
      " 'of' , word not present in labelled spam training data\n",
      "'our',ok\n",
      "'account',ok\n",
      "'the',ok\n",
      "'importance',ok\n",
      " 'of' , word not present in labelled spam training data\n",
      "'physical',ok\n",
      "'activity',ok\n"
     ]
    }
   ],
   "source": [
    "# Ignore the words that you haven't seen in the labelled training data\n",
    "\n",
    "reduced_sentences_spam_test = []\n",
    "\n",
    "for sentence in test_spam_tokenized:\n",
    "    words = []\n",
    "    for word in sentence:\n",
    "        if word in vocab_unique_words_spam:\n",
    "            print(f\"'{word}',ok\")\n",
    "            words.append(word)\n",
    "        elif word in vocab_unique_words_ham:\n",
    "            print(f\"'{word}',ok\")\n",
    "            words.append(word)\n",
    "        else:\n",
    "            print(f\" '{word}' , word not present in labelled spam training data\")\n",
    "    reduced_sentences_spam_test.append(words)\n",
    "            \n",
    "reduced_sentences_ham_test = []\n",
    "\n",
    "for sentence in test_ham_tokenized:\n",
    "    words_ = []\n",
    "    for word in sentence:\n",
    "        if word in vocab_unique_words_spam:\n",
    "            print(f\"'{word}',ok\")\n",
    "            words_.append(word)\n",
    "        elif word in vocab_unique_words_ham:\n",
    "            print(f\"'{word}',ok\")\n",
    "            words_.append(word)\n",
    "        else:\n",
    "            print(f\" '{word}' , word not present in labelled spam training data\")\n",
    "    reduced_sentences_ham_test.append(words_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove\n",
      "remove\n",
      "remove\n",
      "[['benefits', 'our', 'account'], ['importance', 'physical', 'activity']]\n"
     ]
    }
   ],
   "source": [
    "# Stemming - remove non-key words\n",
    "\n",
    "test_spam_stemmed = []\n",
    "non_key = ['us' , 'the' ,'of' ,'your']\n",
    "\n",
    "for email in reduced_sentences_spam_test:\n",
    "    email_stemmed = []\n",
    "    for word in email:\n",
    "        if word in non_key:\n",
    "            print('remove')\n",
    "        else:\n",
    "            email_stemmed.append(word)\n",
    "    test_spam_stemmed.append(email_stemmed)\n",
    "    \n",
    "\n",
    "test_ham_stemmed = []\n",
    "non_key = ['us' , 'the' ,'of' ,'your']\n",
    "\n",
    "for email in reduced_sentences_ham_test:\n",
    "    email_stemmed = []\n",
    "    for word in email:\n",
    "        if word in non_key:\n",
    "            print('remove')\n",
    "        else:\n",
    "            email_stemmed.append(word)\n",
    "    test_ham_stemmed.append(email_stemmed)\n",
    "    \n",
    "print(test_ham_stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify spam test emails\n",
    "\n",
    "def mult(list_):\n",
    "    total_prob = 1\n",
    "    for i in list_:\n",
    "        total_prob = total_prob * i \n",
    "    return total_prob\n",
    "\n",
    "def Bayes(email):\n",
    "    probs = []\n",
    "    for word in email:\n",
    "        Pr_S = prob_spam\n",
    "        print('prob of spam in general',Pr_S)\n",
    "        \n",
    "        try:\n",
    "            pr_WS = dict_spamicity[word]\n",
    "            print(f'prob \"{word}\" is a spam word : {pr_WS}')\n",
    "        except KeyError:\n",
    "            pr_WS = 1 / (total_spam+2)\n",
    "            print(f'prob \"{word}\" is a spam word: {pr_WS}')\n",
    "        \n",
    "        Pr_H = prob_ham\n",
    "        print('prob of ham in general ' , Pr_H)\n",
    "            \n",
    "        try:\n",
    "            pr_WH = dict_hamicity[word]\n",
    "            print(f'prob  \"{word}\" is a ham word',pr_WH)\n",
    "        except KeyError:\n",
    "            pr_WH = 1 / (total_ham + 2)\n",
    "            print(f'prob \"{word}\" is a ham word:',pr_WH)\n",
    "        \n",
    "        prob_word_is_spam_BAYES = (pr_WS*Pr_S) / ( pr_WS*Pr_S + pr_WH * Pr_H ) \n",
    "        print('')\n",
    "        \n",
    "        print(f\"Using Bayes , prob the word '{word}' is spam:{prob_word_is_spam_BAYES}\")\n",
    "        \n",
    "        print(\"#\"*20)\n",
    "        probs.append(prob_word_is_spam_BAYES)\n",
    "    print(f\"All words probabilities for this sentence:{probs}\")\n",
    "    final_classification = mult(probs)\n",
    "        \n",
    "    if final_classification >= 0.5:\n",
    "        print(f\"email is SPAM: with spammy confidence of {final_classification*100}%\")\n",
    "        return final_classification\n",
    "    else:\n",
    "        print(f\"email is HAM: with spammy confidence of {final_classification*100}%\")\n",
    "        return final_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Testing stemmed SPAM email ['password'] :\n",
      "  Test word by word :\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"password\" is a spam word : 0.5\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob \"password\" is a ham word: 0.2\n",
      "\n",
      "Using Bayes , prob the word 'password' is spam:0.7692307692307692\n",
      "####################\n",
      "All words probabilities for this sentence:[0.7692307692307692]\n",
      "email is SPAM: with spammy confidence of 76.92307692307692%\n",
      "\n",
      "  Testing stemmed SPAM email ['vows'] :\n",
      "  Test word by word :\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"vows\" is a spam word: 0.16666666666666666\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob  \"vows\" is a ham word 0.4\n",
      "\n",
      "Using Bayes , prob the word 'vows' is spam:0.35714285714285715\n",
      "####################\n",
      "All words probabilities for this sentence:[0.35714285714285715]\n",
      "email is HAM: with spammy confidence of 35.714285714285715%\n"
     ]
    }
   ],
   "source": [
    "for email in test_spam_stemmed:\n",
    "    print('')\n",
    "    print(f\"  Testing stemmed SPAM email {email} :\")\n",
    "    print('  Test word by word :')\n",
    "    all_word_probs = Bayes(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Testing stemmed Hamail ['benefits', 'our', 'account'] :\n",
      "  Test word by word :\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"benefits\" is a spam word: 0.16666666666666666\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob  \"benefits\" is a ham word 0.4\n",
      "\n",
      "Using Bayes , prob the word 'benefits' is spam:0.35714285714285715\n",
      "####################\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"our\" is a spam word : 0.8333333333333334\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob \"our\" is a ham word: 0.2\n",
      "\n",
      "Using Bayes , prob the word 'our' is spam:0.847457627118644\n",
      "####################\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"account\" is a spam word : 0.3333333333333333\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob \"account\" is a ham word: 0.2\n",
      "\n",
      "Using Bayes , prob the word 'account' is spam:0.689655172413793\n",
      "####################\n",
      "All words probabilities for this sentence:[0.35714285714285715, 0.847457627118644, 0.689655172413793]\n",
      "email is HAM: with spammy confidence of 20.873340569424727%\n",
      "0.20873340569424728\n",
      "\n",
      "  Testing stemmed Hamail ['importance', 'physical', 'activity'] :\n",
      "  Test word by word :\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"importance\" is a spam word: 0.16666666666666666\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob  \"importance\" is a ham word 0.4\n",
      "\n",
      "Using Bayes , prob the word 'importance' is spam:0.35714285714285715\n",
      "####################\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"physical\" is a spam word: 0.16666666666666666\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob  \"physical\" is a ham word 0.4\n",
      "\n",
      "Using Bayes , prob the word 'physical' is spam:0.35714285714285715\n",
      "####################\n",
      "prob of spam in general 0.5714285714285714\n",
      "prob \"activity\" is a spam word: 0.16666666666666666\n",
      "prob of ham in general  0.42857142857142855\n",
      "prob  \"activity\" is a ham word 0.6\n",
      "\n",
      "Using Bayes , prob the word 'activity' is spam:0.2702702702702703\n",
      "####################\n",
      "All words probabilities for this sentence:[0.35714285714285715, 0.35714285714285715, 0.2702702702702703]\n",
      "email is HAM: with spammy confidence of 3.447324875896305%\n",
      "0.03447324875896305\n"
     ]
    }
   ],
   "source": [
    "for email in test_ham_stemmed:\n",
    "    print('')\n",
    "    print(f\"  Testing stemmed Hamail {email} :\")\n",
    "    print('  Test word by word :')\n",
    "    all_word_probs = Bayes(email)\n",
    "    print(all_word_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
